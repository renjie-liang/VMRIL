{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_json(filename):\n",
    "    with open(filename, mode='r', encoding='utf-8') as f:\n",
    "    # with open(filename, mode='r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def save_json(data, filename):\n",
    "    with open(filename, mode='w', encoding='utf-8') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "def load_lines(filename):\n",
    "    with open(filename, mode='r', encoding='utf-8') as f:\n",
    "        return [e.strip(\"\\n\") for e in f.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charades\n",
    "def convert_charades(old_path, new_path, aux_path):\n",
    "    aux_data = load_json(aux_path)\n",
    "    old_data = load_lines(old_path)\n",
    "\n",
    "    new_data = []\n",
    "    for line in old_data:\n",
    "        line = line.lstrip().rstrip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        video_info, sent = line.split('##')\n",
    "        vid, s, e = video_info.split(' ')\n",
    "        duration = aux_data[vid]['duration']\n",
    "\n",
    "        s = max(round(float(s), 2), 0)\n",
    "        e = min(round(float(e), 2), duration)\n",
    "        record = [vid, duration, [s, e], sent]\n",
    "        new_data.append(record)\n",
    "        \n",
    "    save_json(new_data, new_path)\n",
    "\n",
    "    print(old_path, \"->\", new_path)\n",
    "    print(len(old_data), \"->\", len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/dataset/charades/charades_sta_train.txt -> ./data/dataset/charades_gt/train.json\n",
      "12408 -> 12408\n",
      "./data/dataset/charades/charades_sta_test.txt -> ./data/dataset/charades_gt/test.json\n",
      "3720 -> 3720\n"
     ]
    }
   ],
   "source": [
    "aux_path = 'data/dataset/charades/charades.json'\n",
    "\n",
    "old_path = './data/dataset/charades/charades_sta_train.txt'\n",
    "new_path = './data/dataset/charades_gt/train.json'\n",
    "convert_charades(old_path, new_path, aux_path)\n",
    "\n",
    "old_path = './data/dataset/charades/charades_sta_test.txt'\n",
    "new_path = './data/dataset/charades_gt/test.json'\n",
    "convert_charades(old_path, new_path, aux_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ActivityNet\n",
    "def convert_anet(old_path, new_path, vlen_path):\n",
    "    old_data = load_json(old_path)\n",
    "    vlen = load_json(vlen_path)\n",
    "    vids = set(vlen.keys())\n",
    "    \n",
    "    new_data = []\n",
    "    for vid in old_data:\n",
    "        if vid not in vids:\n",
    "            continue\n",
    "\n",
    "        sample = old_data[vid]\n",
    "        timestamps = sample[\"timestamps\"]\n",
    "        sentences = sample[\"sentences\"]\n",
    "        duration = sample[\"duration\"]\n",
    "        for se_frame, sent in zip(timestamps, sentences):\n",
    "            s, e = se_frame\n",
    "            s = max(round(s, 2), 0)\n",
    "            e = min(round(e, 2), duration)\n",
    "            if s > e:\n",
    "                print(\"SKIP:\", s, e)\n",
    "                continue\n",
    "            record = [vid, duration, [s, e], sent]\n",
    "            new_data.append(record)\n",
    "    save_json(new_data, new_path)\n",
    "    print(old_path, \"->\", new_path)\n",
    "    print(len(old_data), \"->\", len(new_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIP: 61.29 60.71\n",
      "SKIP: 173.44 150.31\n",
      "./data/activitynet/train.json -> ./data/anet_i3d_gt/train.json\n",
      "10009 -> 33719\n",
      "./data/activitynet/val_1.json -> ./data/anet_i3d_gt/test.json\n",
      "4917 -> 15753\n"
     ]
    }
   ],
   "source": [
    "vlen_path = \"/storage_fast/rjliang/activitynet/i3d/feature_shapes.json\"\n",
    "\n",
    "old_path = './data/activitynet/train.json'\n",
    "new_path = './data/anet_i3d_gt/train.json'\n",
    "convert_anet(old_path, new_path, vlen_path)\n",
    "\n",
    "old_path = './data/activitynet/val_1.json'\n",
    "new_path = './data/anet_i3d_gt/test.json'\n",
    "convert_anet(old_path, new_path, vlen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tacos\n",
    "def convert_tacos(old_path, new_path):\n",
    "    old_data = load_json(old_path)\n",
    "    vids = list(old_data.keys())\n",
    "    # vids.sort()\n",
    "\n",
    "    new_data = []\n",
    "    for vid in vids:\n",
    "        sample = old_data[vid]\n",
    "        timestamps = sample[\"timestamps\"]\n",
    "        sentences = sample[\"sentences\"]\n",
    "        fps = sample[\"fps\"]\n",
    "        num_frames = sample[\"num_frames\"]\n",
    "        duration = round(num_frames / fps, 2)\n",
    "        for se_frame, sent in zip(timestamps, sentences):\n",
    "            s, e = se_frame\n",
    "            s = max(round(s / num_frames * duration, 2), 0)\n",
    "            e = min(round(e / num_frames * duration, 2), duration)\n",
    "\n",
    "            record = [vid[:-4], duration, [s, e], sent]\n",
    "            new_data.append(record)\n",
    "\n",
    "    save_json(new_data, new_path)\n",
    "    print(old_path, \"->\", new_path)\n",
    "    print(len(old_data), \"->\", len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/dataset/tacos/train.json -> ./data/dataset/tacos_gt/train.json\n",
      "75 -> 9790\n"
     ]
    }
   ],
   "source": [
    "old_path = './data/dataset/tacos/train.json'\n",
    "new_path = './data/dataset/tacos_gt/train.json'\n",
    "\n",
    "convert_tacos(old_path, new_path)\n",
    "\n",
    "# old_path = './data/dataset/tacos/test.json'\n",
    "# new_path = './data/dataset/tacos_gt/test.json'\n",
    "\n",
    "# convert_tacos(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 13:09:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85417aaa996bf384aabef58b87c77e6a0c178545399cda58bd1fcf7e684b91db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
